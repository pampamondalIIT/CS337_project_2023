# CS337 Course Project 

Aim is to convert the hand-signs to text, to help with the accesibility for the needful.
Create a modular code that can be trained on any sign language and that can have a multiple class, so whole things is reuseable and only we need to provide 
the dataset in correct format.

### Presentation 
To go through the presentation open ML\_and\_Mine.pptx

### Important links
- For the medium [article](https://medium.com/howtoai/video-classification-with-cnn-rnn-and-pytorch-abe2f9ee031)


### How to run 
First run the `vid2frame.ipynb` notebook. This will download the dataset as well as make the dataset ready for the model. Finally run the `Final_model_file.ipynb`, we have multiplexed two models here so change the variable `model_type` to run the desired model.

Also sufficient comments are in the code to understand the notebook better.

